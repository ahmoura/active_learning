{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando estratégias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Amostra por incerteza\n",
    "- Amostragem aleatória\n",
    "- Consulta por comitê\n",
    "- Aprendizado passivo\n",
    "- Redução do erro esperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amostra por incerteza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertain_sample(X_raw, y_raw, n_queries):\n",
    "    from modAL.uncertainty import classifier_uncertainty\n",
    "    from modAL.models import ActiveLearner\n",
    "    from modAL.uncertainty import uncertainty_sampling\n",
    "    \n",
    "    knn = KNeighborsClassifier(k)\n",
    "    perfomance_history = []\n",
    "\n",
    "    initial_idx = np.random.choice(range(len(X_raw)), size=k+1, replace=False)\n",
    "    X_train, y_train = X_raw[initial_idx], y_raw[initial_idx]\n",
    "    \n",
    "    knn.fit(X_train,y_train)\n",
    "    \n",
    "    # initialize the learner\n",
    "    learner = ActiveLearner (\n",
    "        estimator=knn,\n",
    "        query_strategy=uncertainty_sampling\n",
    "        #,X_training=X_train, y_training=y_train\n",
    "    )\n",
    "    unqueried_score = learner.score(X_raw, y_raw)\n",
    "\n",
    "    perfomance_history.append(unqueried_score)\n",
    "\n",
    "    total_of_samples = 0\n",
    "    #while learner.score(X_raw, y_raw) < 0.90:\n",
    "    while (total_of_samples != n_queries - 1):\n",
    "        stream_idx = np.random.choice(range(len(X_raw)))\n",
    "        #print(stream_idx)\n",
    "        #print(X_raw[stream_idx].reshape(1, -1))\n",
    "        #print(classifier_uncertainty(learner, X_raw[stream_idx].reshape(1, -1)))\n",
    "        #print(\"----------------------\")\n",
    "        if classifier_uncertainty(learner, X_raw[stream_idx].reshape(1, -1)) > 0:\n",
    "            learner.teach(X_raw[stream_idx].reshape(1, -1), y_raw[stream_idx].reshape(-1, ))\n",
    "            new_score = learner.score(X_raw, y_raw)\n",
    "            perfomance_history.append(new_score)\n",
    "            total_of_samples = total_of_samples + 1\n",
    "\n",
    "    performance_history_total.append(perfomance_history)\n",
    "    legend.append(\"Uncertainty Sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amostragem aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(X_raw, y_raw, n_queries):\n",
    "    performance_history = []\n",
    "    size_of_dataset = X_raw.shape[0]\n",
    "    \n",
    "    for i in range(1,n_queries+1):\n",
    "\n",
    "        training_indices = np.random.randint(low=0, high=size_of_dataset, size=k+i)\n",
    "\n",
    "        X_train = X_raw[training_indices]\n",
    "        y_train = y_raw[training_indices]\n",
    "\n",
    "        X_test = np.delete(X_raw, training_indices, axis=0)\n",
    "        y_test = np.delete(y_raw, training_indices, axis=0)\n",
    "\n",
    "        knn = KNeighborsClassifier(k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        pred = knn.predict(X_test)\n",
    "        performance_history.append(knn.score(X_test,y_test))\n",
    "\n",
    "    performance_history_total.append(performance_history)\n",
    "    legend.append(\"Random Sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consulta por comitê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modAL.models import ActiveLearner, Committee\n",
    "\n",
    "def query_by_committee(X_raw,y_raw,n_queries):\n",
    "\n",
    "    performance_history = []\n",
    "    for i in range(1,n_queries+1):\n",
    "\n",
    "        learner_list = []\n",
    "        X_pool = deepcopy(X_raw)\n",
    "        y_pool = deepcopy(y_raw)\n",
    "\n",
    "        train_idx = np.random.choice(range(X_pool.shape[0]), size=k+i, replace=False)\n",
    "        X_train = X_pool[train_idx]\n",
    "        y_train = y_pool[train_idx]\n",
    "\n",
    "        # creating a reduced copy of the data with the known instances removed\n",
    "        X_pool = np.delete(X_pool, train_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, train_idx)\n",
    "\n",
    "        # initializing learner\n",
    "        learner = ActiveLearner(\n",
    "            estimator=KNeighborsClassifier(k),\n",
    "            X_training=X_train, y_training=y_train\n",
    "        )\n",
    "        learner_list.append(learner)\n",
    "\n",
    "        # assembling the committee\n",
    "        committee = Committee(learner_list=learner_list)\n",
    "\n",
    "        # query by committee\n",
    "        for idx in range(n_queries):\n",
    "            query_idx, query_instance = committee.query(X_pool)\n",
    "            committee.teach(\n",
    "                X=X_pool[query_idx].reshape(1, -1),\n",
    "                y=y_pool[query_idx].reshape(1, )\n",
    "            )\n",
    "\n",
    "            # remove queried instance from pool\n",
    "            X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "            y_pool = np.delete(y_pool, query_idx)\n",
    "        performance_history.append(committee.score(X_raw, y_raw))\n",
    "    performance_history_total.append(performance_history)\n",
    "    legend.append(\"Query by committee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado passivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def passive_learning(X_raw, y_raw, n_queries):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_raw, y_raw,test_size=0.3,random_state=1)\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    knn.fit(X_train, Y_train)\n",
    "\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    scores = cross_val_score(knn, X_raw, y_raw, cv=n_queries, scoring='accuracy')\n",
    "    performance_history_total.append(scores)\n",
    "    legend.append(\"Passive learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amostragem baseada na reserva de exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_based_sampling(X_raw, y_raw, n_queries):\n",
    "    X_raw = deepcopy(X_raw)\n",
    "    y_raw = deepcopy(y_raw)\n",
    "\n",
    "    # Isolate our examples for our labeled dataset.\n",
    "    n_labeled_examples = X_raw.shape[0]\n",
    "    training_indices = np.random.randint(low=0, high=n_labeled_examples, size=k)\n",
    "\n",
    "    X_train = X_raw[training_indices]\n",
    "    y_train = y_raw[training_indices]\n",
    "\n",
    "    # Isolate the non-training examples we'll be querying.\n",
    "    X_pool = np.delete(X_raw, training_indices, axis=0)\n",
    "    y_pool = np.delete(y_raw, training_indices, axis=0)\n",
    "    \n",
    "    \n",
    "    # Specify our core estimator along with it's active learning model.\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    learner = ActiveLearner(estimator=knn, X_training=X_train, y_training=y_train)\n",
    "    \n",
    "    unqueried_score = learner.score(X_raw, y_raw)\n",
    "\n",
    "    performance_history = [unqueried_score]\n",
    "\n",
    "    # Allow our model to query our unlabeled dataset for the most\n",
    "    # informative points according to our query strategy (uncertainty sampling).\n",
    "    for index in range(n_queries):\n",
    "      query_index, query_instance = learner.query(X_pool)\n",
    "\n",
    "      # Teach our ActiveLearner model the record it has requested.\n",
    "      X, y = X_pool[query_index].reshape(1, -1), y_pool[query_index].reshape(1, )\n",
    "      learner.teach(X=X, y=y)\n",
    "\n",
    "      # Remove the queried instance from the unlabeled pool.\n",
    "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index)\n",
    "\n",
    "      # Calculate and report our model's accuracy.\n",
    "      model_accuracy = learner.score(X_raw, y_raw)\n",
    "\n",
    "      # Save our model's performance for plotting.\n",
    "      performance_history.append(model_accuracy)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    predictions = learner.predict(X_raw)    \n",
    "    performance_history_total.append(performance_history)\n",
    "    legend.append(\"Pool-based Sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando as estratégias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strategies_acc(performance_history_total, legend, title):\n",
    "    fig, ax = plt.subplots(figsize=(8.5, 6), dpi=130)\n",
    "\n",
    "    for idx,pht in enumerate(performance_history_total):\n",
    "        ax.plot(pht)\n",
    "        ax.scatter(range(len(pht)), pht, s=13)\n",
    "\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "    ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax.set_title(title + \" - Classification accuracy with {n_queries} queries\".format(n_queries = n_queries))\n",
    "    ax.set_xlabel('Query iteration')\n",
    "    ax.set_ylabel('Classification Accuracy')\n",
    "    ax.legend(legend, loc='lower right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-acbfa814b0c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mperformance_history_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0muncertain_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_queries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mrandom_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_queries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mquery_by_committee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_queries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f570ca89363c>\u001b[0m in \u001b[0;36muncertain_sample\u001b[0;34m(X_raw, y_raw, n_queries)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassifier_uncertainty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstream_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstream_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstream_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mnew_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mperfomance_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mtotal_of_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_of_samples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/active_learning/act_learn/lib/python3.7/site-packages/modAL/models/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, **score_kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mscore\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mscore_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/active_learning/act_learn/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/active_learning/act_learn/lib/python3.7/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/active_learning/act_learn/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m             )\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 3"
     ]
    }
   ],
   "source": [
    "n_queries = 10\n",
    "k = 3\n",
    "\n",
    "#title = [\"IRIS\", \"DIGITS\", \"WINE\", \"BREAST CANCER\"]\n",
    "title = [\"IRIS\", \"WINE\"]\n",
    "#datasets = [load_iris(), load_digits(), load_wine(), load_breast_cancer()]\n",
    "datasets = [load_iris(), load_wine()]\n",
    "\n",
    "for idx,dataset in enumerate(datasets): \n",
    "    data = dataset\n",
    "    X_raw = data['data']\n",
    "    y_raw = data['target']\n",
    "    legend = []\n",
    "    performance_history_total = []\n",
    "\n",
    "    uncertain_sample(deepcopy(X_raw), deepcopy(y_raw), n_queries)\n",
    "    random_sampling(deepcopy(X_raw), deepcopy(y_raw), n_queries)\n",
    "    query_by_committee(deepcopy(X_raw),deepcopy(y_raw),n_queries)\n",
    "    passive_learning(deepcopy(X_raw), deepcopy(y_raw), n_queries)\n",
    "    pool_based_sampling(deepcopy(X_raw), deepcopy(y_raw), n_queries)\n",
    "    plot_strategies_acc(performance_history_total, legend, title[idx])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = load_breast_cancer()\n",
    "X_raw = data['data']\n",
    "y_raw = data['target']\n",
    "\n",
    "from modAL.uncertainty import classifier_uncertainty\n",
    "from modAL.models import ActiveLearner\n",
    "\n",
    "knn = KNeighborsClassifier(k)\n",
    "perfomance_history = []\n",
    "\n",
    "initial_idx = np.random.choice(range(len(X_raw)), size=k+1, replace=False)\n",
    "X_train, y_train = X_raw[initial_idx], y_raw[initial_idx]\n",
    "\n",
    "# initialize the learner\n",
    "learner = ActiveLearner(\n",
    "    estimator=knn,\n",
    "    X_training=X_train, y_training=y_train\n",
    ")\n",
    "unqueried_score = learner.score(X_raw, y_raw)\n",
    "\n",
    "perfomance_history.append(unqueried_score)\n",
    "\n",
    "total_of_samples = 0\n",
    "#while learner.score(X_raw, y_raw) < 0.90:\n",
    "while (total_of_samples != n_queries - 1):\n",
    "    stream_idx = np.random.choice(range(len(X_raw)))\n",
    "    #print(stream_idx)\n",
    "    #print(X_raw[stream_idx].reshape(1, -1))\n",
    "    print(classifier_uncertainty(learner, X_raw[stream_idx].reshape(1, -1)))\n",
    "    #print(\"----------------------\")\n",
    "    if classifier_uncertainty(learner, X_raw[stream_idx].reshape(1, -1)) > 0:\n",
    "        learner.teach(X_raw[stream_idx].reshape(1, -1), y_raw[stream_idx].reshape(-1, ))\n",
    "        new_score = learner.score(X_raw, y_raw)\n",
    "        perfomance_history.append(new_score)\n",
    "        total_of_samples = total_of_samples + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X_raw = data['data']\n",
    "y_raw = data['target']\n",
    "\n",
    "from modAL.expected_error import expected_error_reduction\n",
    "from modAL.models import ActiveLearner\n",
    "\n",
    "knn = KNeighborsClassifier(k)\n",
    "perfomance_history = []\n",
    "\n",
    "initial_idx = np.random.choice(range(len(X_raw)), size=k+1, replace=False)\n",
    "X_train, y_train = X_raw[initial_idx], y_raw[initial_idx]\n",
    "\n",
    "learner = ActiveLearner(\n",
    "    estimator=knn,\n",
    "    X_training=X_train, y_training=y_train\n",
    ")\n",
    "unqueried_score = learner.score(X_raw, y_raw)\n",
    "\n",
    "perfomance_history.append(unqueried_score)\n",
    "\n",
    "total_of_samples = 0\n",
    "#while learner.score(X_raw, y_raw) < 0.90:\n",
    "while (total_of_samples != n_queries - 1):\n",
    "    stream_idx = np.random.choice(range(len(X_raw)))\n",
    "    #print(stream_idx)\n",
    "    #print(X_raw[stream_idx].reshape(1, -1))\n",
    "    print(expected_error_reduction(learner, X_raw[stream_idx].reshape(1, -1)))\n",
    "    #print(\"----------------------\")\n",
    "    if expected_error_reduction(learner, X_raw[stream_idx].reshape(1, -1)) > 0:\n",
    "        learner.teach(X_raw[stream_idx].reshape(1, -1), y_raw[stream_idx].reshape(-1, ))\n",
    "        new_score = learner.score(X_raw, y_raw)\n",
    "        perfomance_history.append(new_score)\n",
    "        total_of_samples = total_of_samples + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modAL.models import ActiveLearner\n",
    "?ActiveLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
