{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando estratégias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Amostra por incerteza\n",
    "- Amostragem aleatória\n",
    "- Consulta por comitê\n",
    "- Aprendizado passivo\n",
    "- Redução do erro esperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'over': 'warn', 'under': 'ignore', 'invalid': 'ignore'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amostra por incerteza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertain_sampling(X_raw, y_raw, idx_data, idx_bag, classifier, init_size, n_queries):\n",
    "    \n",
    "    from modAL.uncertainty import classifier_uncertainty\n",
    "    sample_size = 0 #contador de amostras utilizadas pela estratégia\n",
    "    performance_history = []\n",
    "    start = timer()\n",
    "    \n",
    "    # parte randomica inicial da estratégia\n",
    "    initial_idx = np.random.choice(range(len(idx_data[idx_bag][0])), size=init_size, replace=False)\n",
    "    X_train, y_train = X_raw[idx_data[idx_bag][0][initial_idx]], y_raw[idx_data[idx_bag][0][initial_idx]]\n",
    "    X_test, y_test = X_raw[idx_data[idx_bag][1]], y_raw[idx_data[idx_bag][1]]\n",
    "    \n",
    "    sample_size = sample_size + len(X_train)\n",
    "\n",
    "    classifier.fit(X_train,y_train)\n",
    "\n",
    "    learner = ActiveLearner (\n",
    "        estimator=classifier,\n",
    "        query_strategy=uncertainty_sampling\n",
    "    )\n",
    "    uncertain_sample_score = learner.score(X_test, y_test)\n",
    "\n",
    "    performance_history.append(uncertain_sample_score)\n",
    "\n",
    "    total_of_samples = 0\n",
    "    while (total_of_samples != n_queries - 1):\n",
    "        \n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, train_size=0.03)\n",
    "        \n",
    "        idx = np.random.choice(range(len(idx_data[idx_bag][0])), size=init_size, replace=False)\n",
    "        X_train, y_train = X_raw[idx_data[idx_bag][0][idx]], y_raw[idx_data[idx_bag][0][idx]]\n",
    "        #print(\"WHILE\", classifier_uncertainty(learner, X_train[0].reshape(1,-1)))\n",
    "        if classifier_uncertainty(learner, X_train[0].reshape(1,-1)) > 0.2: #ASK04\n",
    "            #print(\"IF\", learner.score(X_test, y_test))\n",
    "            sample_size = sample_size + len(X_train)\n",
    "            learner.teach(X_train, y_train)\n",
    "            uncertain_sample_score = learner.score(X_test, y_test)\n",
    "            performance_history.append(uncertain_sample_score)\n",
    "            #print(\"Uncertainty Sampling score: \", uncertain_sample_score)\n",
    "            performance_history.append(uncertain_sample_score)    \n",
    "        total_of_samples = total_of_samples + 1 #ASK05\n",
    "    \n",
    "    end = timer()\n",
    "    time_elapsed = end - start\n",
    "    \n",
    "    return { \"performance_history\": performance_history, \n",
    "             \"time_elapsed\": time_elapsed,\n",
    "             \"sample_size\": sample_size, # RETORNAR TODAS AS AMOSTRAS DE CADA PERFORMANCE OU SÓ DO ULTIMO\n",
    "             \"Strategy\": \"Uncertainty Sampling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amostragem aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(X_raw, y_raw, idx_data, idx_bag, classifier, init_size, n_queries):\n",
    "        \n",
    "    sample_size = 0 #contador de amostras utilizadas pela estratégia\n",
    "    performance_history = []\n",
    "    start = timer()\n",
    "\n",
    "    for i in range(1,n_queries+1):\n",
    "\n",
    "        #high = X_raw.shape[0] = qtd amostras no dataset\n",
    "        training_indices = np.random.randint(low=0, high=len(X_raw[idx_data[idx_bag][0]]), size=k+i) #high = qtd elementos na bag\n",
    "        sample_size = sample_size + len(training_indices)\n",
    "\n",
    "        X_train = X_raw[idx_data[idx_bag][0][training_indices]] #ASK06\n",
    "        y_train = y_raw[idx_data[idx_bag][0][training_indices]]\n",
    "\n",
    "        X_test = np.delete(X_raw, idx_data[idx_bag][0][training_indices], axis=0)\n",
    "        y_test = np.delete(y_raw, idx_data[idx_bag][0][training_indices], axis=0)\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        #pred = classifier.predict(X_test)\n",
    "        #print(\"Random Sampling score: \", knn.score(X_test,y_test))\n",
    "        performance_history.append(classifier.score(X_test,y_test))\n",
    "\n",
    "        \n",
    "    end = timer()\n",
    "    time_elapsed = end - start\n",
    "\n",
    "    return { \"performance_history\": performance_history, \n",
    "         \"time_elapsed\": time_elapsed,\n",
    "         \"sample_size\": sample_size, # RETORNAR TODAS AS AMOSTRAS DE CADA PERFORMANCE OU SÓ DO ULTIMO\n",
    "         \"Strategy\": \"Random Sampling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consulta por comitê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def query_by_committee(X_raw, y_raw, idx_data, idx_bag, classifier, init_size, n_queries):\n",
    "\n",
    "    from modAL.models import ActiveLearner, Committee\n",
    "    from modAL.disagreement import vote_entropy_sampling\n",
    "\n",
    "    sample_size = 0 #contador de amostras utilizadas pela estratégia\n",
    "    performance_history = []\n",
    "    start = timer()\n",
    "\n",
    "\n",
    "    for i in range(1,n_queries+1):\n",
    "\n",
    "        learner_list = []\n",
    "\n",
    "        for j in range(1,n_queries+1): # Loop para criação do comitê\n",
    "\n",
    "            X_train, _, y_train, _ = train_test_split(X_raw[idx_data[idx_bag][0]], y_raw[idx_data[idx_bag][0]], train_size=0.03)\n",
    "            sample_size = sample_size + len(X_train)\n",
    "            \n",
    "            # initializing learner\n",
    "            learner = ActiveLearner(\n",
    "                estimator=which_classifier(init_size),\n",
    "                query_strategy=uncertainty_sampling,\n",
    "                X_training = X_train, y_training = y_train \n",
    "            )\n",
    "            learner_list.append(learner)\n",
    "\n",
    "        # assembling the committee\n",
    "        committee = Committee(\n",
    "            learner_list=learner_list,\n",
    "            query_strategy=vote_entropy_sampling)\n",
    "\n",
    "        X_pool, y_pool = X_raw[idx_data[idx_bag][0]], y_raw[idx_data[idx_bag][0]]\n",
    "\n",
    "        # query by committee\n",
    "        for idx in range(n_queries):\n",
    "            query_idx, query_instance = committee.query(X_pool, n_instances = k+1)\n",
    "            sample_size = sample_size + len(query_idx)\n",
    "            committee.teach(\n",
    "                X=X_pool[query_idx],\n",
    "                y=y_pool[query_idx]\n",
    "            )\n",
    "\n",
    "            X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "            y_pool = np.delete(y_pool, query_idx)\n",
    "        performance_history.append(committee.score(X_pool, y_pool))\n",
    "\n",
    "        #print(idx, n_queries, \"Query by Committee: \", committee.score(X_pool, y_pool))\n",
    "\n",
    "        \n",
    "    end = timer()\n",
    "    time_elapsed = end - start\n",
    "\n",
    "    return { \"performance_history\": performance_history, \n",
    "         \"time_elapsed\": time_elapsed,\n",
    "         \"sample_size\": sample_size, # RETORNAR TODAS AS AMOSTRAS DE CADA PERFORMANCE OU SÓ DO ULTIMO\n",
    "         \"Strategy\": \"Query by Committee\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_dataset(dataset = \"iris\", n_splits = 5):\n",
    "    \n",
    "    # Futuramente essa etapa será ajustada para receber qualquer dataset (ou lista com datasets)\n",
    "    if (dataset == \"iris\"):\n",
    "        data = load_iris()\n",
    "        X_raw = data['data']\n",
    "        y_raw = data['target']\n",
    "        \n",
    "    # cross validation bags\n",
    "    data_cv = ShuffleSplit(n_splits= n_splits, test_size=0.3, random_state=0) #n_splits\n",
    "    \n",
    "    # extraindo ids do data_cv\n",
    "    idx_data = []\n",
    "    for train_index, test_index in data_cv.split(X_raw):\n",
    "            idx_data.append([train_index, test_index])\n",
    "\n",
    "    return X_raw, y_raw, idx_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_classifier(parameters, classifier = 'knn'):\n",
    "    \n",
    "    if (classifier == 'knn'):\n",
    "        return KNeighborsClassifier(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_queries = 10 # cost\n",
    "n_splits = 5 # number of bags cv\n",
    "total_performance_history = []\n",
    "k = 3 #parameter to knn classifier\n",
    "\n",
    "idx_bag = 1\n",
    "\n",
    "classifier = which_classifier(k)\n",
    "X_raw, y_raw, idx_data = which_dataset()\n",
    "\n",
    "#para cada i em idx_bag (\"n_splits\") (1 a 5)\n",
    "for idx_bag in range(n_splits):\n",
    "    total_performance_history.append(uncertain_sampling(deepcopy(X_raw), deepcopy(y_raw), idx_data, idx_bag, classifier, k, n_queries))\n",
    "for idx_bag in range(n_splits):\n",
    "    total_performance_history.append(random_sampling(deepcopy(X_raw), deepcopy(y_raw), idx_data, idx_bag, classifier, k, n_queries))\n",
    "for idx_bag in range(n_splits):\n",
    "    total_performance_history.append(query_by_committee(deepcopy(X_raw), deepcopy(y_raw), idx_data, idx_bag, classifier, k, n_queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'performance_history': [0.35555555555555557,\n",
       "   0.35555555555555557,\n",
       "   0.35555555555555557,\n",
       "   0.8,\n",
       "   0.8,\n",
       "   0.9111111111111111,\n",
       "   0.9111111111111111,\n",
       "   0.9111111111111111,\n",
       "   0.9111111111111111],\n",
       "  'time_elapsed': 0.06632492300013837,\n",
       "  'sample_size': 15,\n",
       "  'Strategy': 'Uncertainty Sampling'},\n",
       " {'performance_history': [0.26666666666666666,\n",
       "   0.37777777777777777,\n",
       "   0.37777777777777777,\n",
       "   0.6444444444444445,\n",
       "   0.6444444444444445,\n",
       "   0.6444444444444445,\n",
       "   0.6444444444444445,\n",
       "   0.8444444444444444,\n",
       "   0.8444444444444444],\n",
       "  'time_elapsed': 0.04442180600017309,\n",
       "  'sample_size': 15,\n",
       "  'Strategy': 'Uncertainty Sampling'},\n",
       " {'performance_history': [0.26666666666666666,\n",
       "   0.35555555555555557,\n",
       "   0.35555555555555557,\n",
       "   0.6222222222222222,\n",
       "   0.6222222222222222,\n",
       "   0.6222222222222222,\n",
       "   0.6222222222222222,\n",
       "   0.9111111111111111,\n",
       "   0.9111111111111111],\n",
       "  'time_elapsed': 0.039439699000467954,\n",
       "  'sample_size': 15,\n",
       "  'Strategy': 'Uncertainty Sampling'},\n",
       " {'performance_history': [0.26666666666666666,\n",
       "   0.37777777777777777,\n",
       "   0.37777777777777777,\n",
       "   0.4888888888888889,\n",
       "   0.4888888888888889,\n",
       "   0.8888888888888888,\n",
       "   0.8888888888888888,\n",
       "   0.8666666666666667,\n",
       "   0.8666666666666667],\n",
       "  'time_elapsed': 0.03690762699989136,\n",
       "  'sample_size': 15,\n",
       "  'Strategy': 'Uncertainty Sampling'},\n",
       " {'performance_history': [0.24444444444444444,\n",
       "   0.4,\n",
       "   0.4,\n",
       "   0.9555555555555556,\n",
       "   0.9555555555555556,\n",
       "   0.9555555555555556,\n",
       "   0.9555555555555556,\n",
       "   0.8888888888888888,\n",
       "   0.8888888888888888,\n",
       "   0.9555555555555556,\n",
       "   0.9555555555555556],\n",
       "  'time_elapsed': 0.03200132299934921,\n",
       "  'sample_size': 18,\n",
       "  'Strategy': 'Uncertainty Sampling'},\n",
       " {'performance_history': [0.3287671232876712,\n",
       "   0.6620689655172414,\n",
       "   0.6527777777777778,\n",
       "   0.6527777777777778,\n",
       "   0.9295774647887324,\n",
       "   0.6549295774647887,\n",
       "   0.8085106382978723,\n",
       "   0.8776978417266187,\n",
       "   0.9496402877697842,\n",
       "   0.9130434782608695],\n",
       "  'time_elapsed': 0.10071315400000458,\n",
       "  'sample_size': 85,\n",
       "  'Strategy': 'Random Sampling'},\n",
       " {'performance_history': [0.6643835616438356,\n",
       "   0.4896551724137931,\n",
       "   0.6597222222222222,\n",
       "   0.6503496503496503,\n",
       "   0.823943661971831,\n",
       "   0.5985915492957746,\n",
       "   0.65,\n",
       "   0.920863309352518,\n",
       "   0.927536231884058,\n",
       "   0.9347826086956522],\n",
       "  'time_elapsed': 0.12906157700035692,\n",
       "  'sample_size': 85,\n",
       "  'Strategy': 'Random Sampling'},\n",
       " {'performance_history': [0.3287671232876712,\n",
       "   0.6551724137931034,\n",
       "   0.9444444444444444,\n",
       "   0.5034965034965035,\n",
       "   0.9366197183098591,\n",
       "   0.9078014184397163,\n",
       "   0.6428571428571429,\n",
       "   0.6474820143884892,\n",
       "   0.920863309352518,\n",
       "   0.9492753623188406],\n",
       "  'time_elapsed': 0.09035016800044104,\n",
       "  'sample_size': 85,\n",
       "  'Strategy': 'Random Sampling'},\n",
       " {'performance_history': [0.3219178082191781,\n",
       "   0.5862068965517241,\n",
       "   0.6597222222222222,\n",
       "   0.8741258741258742,\n",
       "   0.6503496503496503,\n",
       "   0.6524822695035462,\n",
       "   0.9285714285714286,\n",
       "   0.9642857142857143,\n",
       "   0.8695652173913043,\n",
       "   0.9136690647482014],\n",
       "  'time_elapsed': 0.08853535100024601,\n",
       "  'sample_size': 85,\n",
       "  'Strategy': 'Random Sampling'},\n",
       " {'performance_history': [0.3287671232876712,\n",
       "   0.6620689655172414,\n",
       "   0.6597222222222222,\n",
       "   0.5174825174825175,\n",
       "   0.795774647887324,\n",
       "   0.5633802816901409,\n",
       "   0.8785714285714286,\n",
       "   0.9574468085106383,\n",
       "   0.9130434782608695,\n",
       "   0.9562043795620438],\n",
       "  'time_elapsed': 0.09115193900015583,\n",
       "  'sample_size': 85,\n",
       "  'Strategy': 'Random Sampling'},\n",
       " {'performance_history': [0.9846153846153847,\n",
       "   0.9846153846153847,\n",
       "   0.9846153846153847,\n",
       "   0.9846153846153847,\n",
       "   0.9846153846153847,\n",
       "   0.9538461538461539,\n",
       "   0.9538461538461539,\n",
       "   0.9846153846153847,\n",
       "   1.0,\n",
       "   0.9538461538461539],\n",
       "  'time_elapsed': 7.607255283000086,\n",
       "  'sample_size': 700,\n",
       "  'Strategy': 'Query by Committee'},\n",
       " {'performance_history': [1.0,\n",
       "   0.9846153846153847,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9846153846153847,\n",
       "   0.9692307692307692,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9846153846153847,\n",
       "   0.9846153846153847],\n",
       "  'time_elapsed': 6.942601534999994,\n",
       "  'sample_size': 700,\n",
       "  'Strategy': 'Query by Committee'},\n",
       " {'performance_history': [0.9538461538461539,\n",
       "   0.9846153846153847,\n",
       "   0.9538461538461539,\n",
       "   0.9692307692307692,\n",
       "   0.9538461538461539,\n",
       "   0.9538461538461539,\n",
       "   0.9846153846153847,\n",
       "   0.9538461538461539,\n",
       "   0.9538461538461539,\n",
       "   0.9846153846153847],\n",
       "  'time_elapsed': 6.848729419999472,\n",
       "  'sample_size': 700,\n",
       "  'Strategy': 'Query by Committee'},\n",
       " {'performance_history': [0.9846153846153847,\n",
       "   0.9846153846153847,\n",
       "   0.9846153846153847,\n",
       "   0.9846153846153847,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.9846153846153847,\n",
       "   0.9846153846153847,\n",
       "   1.0,\n",
       "   0.9692307692307692],\n",
       "  'time_elapsed': 6.770022658999551,\n",
       "  'sample_size': 700,\n",
       "  'Strategy': 'Query by Committee'},\n",
       " {'performance_history': [0.9538461538461539,\n",
       "   0.9846153846153847,\n",
       "   0.9384615384615385,\n",
       "   0.9538461538461539,\n",
       "   0.9538461538461539,\n",
       "   0.9384615384615385,\n",
       "   0.9846153846153847,\n",
       "   0.9538461538461539,\n",
       "   0.9538461538461539,\n",
       "   0.9692307692307692],\n",
       "  'time_elapsed': 6.793912233999436,\n",
       "  'sample_size': 700,\n",
       "  'Strategy': 'Query by Committee'}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_performance_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(total_performance_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>performance_history</th>\n",
       "      <th>time_elapsed</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>Strategy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.066325</td>\n",
       "      <td>15</td>\n",
       "      <td>Uncertainty Sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.066325</td>\n",
       "      <td>15</td>\n",
       "      <td>Uncertainty Sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.066325</td>\n",
       "      <td>15</td>\n",
       "      <td>Uncertainty Sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.066325</td>\n",
       "      <td>15</td>\n",
       "      <td>Uncertainty Sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.066325</td>\n",
       "      <td>15</td>\n",
       "      <td>Uncertainty Sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.938462</td>\n",
       "      <td>6.793912</td>\n",
       "      <td>700</td>\n",
       "      <td>Query by Committee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.984615</td>\n",
       "      <td>6.793912</td>\n",
       "      <td>700</td>\n",
       "      <td>Query by Committee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.953846</td>\n",
       "      <td>6.793912</td>\n",
       "      <td>700</td>\n",
       "      <td>Query by Committee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.953846</td>\n",
       "      <td>6.793912</td>\n",
       "      <td>700</td>\n",
       "      <td>Query by Committee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.969231</td>\n",
       "      <td>6.793912</td>\n",
       "      <td>700</td>\n",
       "      <td>Query by Committee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   performance_history  time_elapsed  sample_size              Strategy\n",
       "0             0.355556      0.066325           15  Uncertainty Sampling\n",
       "0             0.355556      0.066325           15  Uncertainty Sampling\n",
       "0             0.355556      0.066325           15  Uncertainty Sampling\n",
       "0                  0.8      0.066325           15  Uncertainty Sampling\n",
       "0                  0.8      0.066325           15  Uncertainty Sampling\n",
       "..                 ...           ...          ...                   ...\n",
       "14            0.938462      6.793912          700    Query by Committee\n",
       "14            0.984615      6.793912          700    Query by Committee\n",
       "14            0.953846      6.793912          700    Query by Committee\n",
       "14            0.953846      6.793912          700    Query by Committee\n",
       "14            0.969231      6.793912          700    Query by Committee\n",
       "\n",
       "[147 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.explode('performance_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://seaborn.pydata.org/examples/scatterplot_sizes.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
