{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modAL + pyhard- Comparando estratégias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Amostra por incerteza\n",
    "- Amostragem aleatória\n",
    "- Consulta por comitê\n",
    "- Aprendizado passivo\n",
    "- Redução do erro esperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i set_environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i importing_libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i importing_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estatratégias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amostra por incerteza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(learner, X, y_true, average = None):\n",
    "    y_pred = learner.predict(X)\n",
    "    return metrics.f1_score(y_true, y_pred, average = average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertain_sampling(X_raw, y_raw, idx_data, idx_bag, classifier, init_size, cost):\n",
    "    \n",
    "    from modAL.uncertainty import classifier_uncertainty\n",
    "    \n",
    "    sample_size = 0 #contador de amostras utilizadas pela estratégia\n",
    "    accuracy_history = []\n",
    "    f1_history = []\n",
    "    start = timer()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_raw[idx_data[idx_bag][TRAIN]], y_raw[idx_data[idx_bag][TRAIN]], train_size= len(np.unique(y_raw)) + init_size, stratify = y_raw[idx_data[idx_bag][TRAIN]])\n",
    "    \n",
    "    sample_size = sample_size + len(X_train)\n",
    "\n",
    "    learner = ActiveLearner (\n",
    "        estimator= which_classifier(classifier), #cls,\n",
    "        query_strategy=uncertainty_sampling,\n",
    "        X_training = X_train, y_training = y_train # AL AJUSTA O CLASSIFIER \n",
    "    )\n",
    "    \n",
    "    accuracy_history.append(learner.score(X_test, y_test))\n",
    "    f1_history.append(compute_f1(learner, X_test, y_test, \"weighted\"))\n",
    "\n",
    "    total_of_samples = 1\n",
    "    while (total_of_samples != cost):\n",
    "        \n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, train_size=0.03)\n",
    "        \n",
    "        idx = np.random.choice(range(len(idx_data[idx_bag][TRAIN])), size=init_size, replace=False)\n",
    "        X_train, y_train = X_raw[idx_data[idx_bag][TRAIN][idx]], y_raw[idx_data[idx_bag][TRAIN][idx]]\n",
    "        \n",
    "        if classifier_uncertainty(learner, X_train[0].reshape(1,-1)) > 0.2:\n",
    "            #print(\"IF\", learner.score(X_test, y_test))\n",
    "            sample_size = sample_size + len(X_train)\n",
    "            learner.teach(X_train, y_train)\n",
    "        accuracy_history.append(learner.score(X_test, y_test))\n",
    "        f1_history.append(compute_f1(learner, X_test, y_test, \"weighted\"))\n",
    "        total_of_samples = total_of_samples + 1\n",
    "    \n",
    "    end = timer()\n",
    "    time_elapsed = end - start\n",
    "    \n",
    "    return { \"accuracy_history\": accuracy_history,\n",
    "             \"f1_history\": f1_history,\n",
    "             \"auc_history\": \"auc_history[-1]\",\n",
    "             \"package\": \"modAL\",\n",
    "             \"time_elapsed\": time_elapsed,\n",
    "             \"classifier\": classifier,\n",
    "             \"sample_size\": sample_size / len(X_raw), # RETORNAR TODAS AS AMOSTRAS DE CADA PERFORMANCE OU SÓ DO ULTIMO\n",
    "             \"Strategy\": \"Uncertain Sampling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amostragem aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(X_raw, y_raw, idx_data, idx_bag, classifier, init_size, cost):\n",
    "        \n",
    "    sample_size = 0 #contador de amostras utilizadas pela estratégia\n",
    "    accuracy_history = []\n",
    "    f1_history = []\n",
    "    start = timer()\n",
    "\n",
    "    for i in range(1, cost+1):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_raw[idx_data[idx_bag][TRAIN]], y_raw[idx_data[idx_bag][TRAIN]], train_size= len(np.unique(y_raw)) + init_size, stratify = y_raw[idx_data[idx_bag][TRAIN]])\n",
    "        sample_size = sample_size + len(X_train)\n",
    "        \n",
    "        cls = which_classifier(classifier)\n",
    "        cls.fit(X_train, y_train)\n",
    "\n",
    "        accuracy_history.append(cls.score(X_test,y_test))\n",
    "        f1_history.append(compute_f1(cls, X_test, y_test, \"weighted\"))\n",
    "\n",
    "        \n",
    "    end = timer()\n",
    "    time_elapsed = end - start\n",
    "\n",
    "    return { \"accuracy_history\": accuracy_history,\n",
    "         \"f1_history\": f1_history,\n",
    "         \"auc_history\": \"auc_history[-1]\",\n",
    "         \"package\": \"modAL\",\n",
    "         \"time_elapsed\": time_elapsed,\n",
    "         \"classifier\": classifier,\n",
    "         \"sample_size\": sample_size / len(X_raw),\n",
    "         \"Strategy\": \"Random Sampling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consulta por comitê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def query_by_committee(X_raw, y_raw, idx_data, idx_bag, classifier, init_size, cost):\n",
    "\n",
    "    from modAL.models import ActiveLearner, Committee\n",
    "    from modAL.disagreement import vote_entropy_sampling\n",
    "\n",
    "    sample_size = 0 #contador de amostras utilizadas pela estratégia\n",
    "    accuracy_history = []\n",
    "    f1_history = []\n",
    "    start = timer()\n",
    "\n",
    "    learner_list = []\n",
    "\n",
    "    for j in range(1, cost+1): # Loop para criação do comitê\n",
    "\n",
    "        X_train, X_pool, y_train, y_pool = train_test_split(X_raw[idx_data[idx_bag][TRAIN]], y_raw[idx_data[idx_bag][TRAIN]], train_size= len(np.unique(y_raw)) + init_size, stratify = y_raw[idx_data[idx_bag][TRAIN]])\n",
    "        sample_size = sample_size + len(X_train)\n",
    "\n",
    "        # initializing learner\n",
    "        learner = ActiveLearner(\n",
    "            estimator= which_classifier(classifier),\n",
    "            X_training = X_train, y_training = y_train \n",
    "        )\n",
    "        learner_list.append(learner)\n",
    "\n",
    "    # assembling the committee\n",
    "    committee = Committee(\n",
    "        learner_list=learner_list,\n",
    "        query_strategy=vote_entropy_sampling)\n",
    "    \n",
    "    # query by committee\n",
    "    for idx in range(cost):\n",
    "        # print(\"\\t Size of X_pool:\", len(X_pool))\n",
    "        query_idx, query_instance = committee.query(X_pool, n_instances = init_size+1)\n",
    "        sample_size = sample_size + len(query_idx)\n",
    "        \n",
    "        committee.teach(\n",
    "            X = X_pool[query_idx],\n",
    "            y = y_pool[query_idx]\n",
    "        )\n",
    "\n",
    "        X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, query_idx)\n",
    "\n",
    "        accuracy_history.append(committee.score(X_pool, y_pool))\n",
    "        f1_history.append(compute_f1(committee, X_pool, y_pool, \"weighted\"))\n",
    "\n",
    "        \n",
    "    end = timer()\n",
    "    time_elapsed = end - start\n",
    "\n",
    "    return { \"accuracy_history\": accuracy_history,\n",
    "         \"f1_history\": f1_history,\n",
    "         \"auc_history\": \"auc_history[-1]\",\n",
    "         \"package\": \"modAL\",\n",
    "         \"time_elapsed\": time_elapsed,\n",
    "         \"classifier\": classifier,\n",
    "         \"sample_size\": sample_size / len(X_raw),\n",
    "         \"Strategy\": \"Query by Committee\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Error Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_error_reduction(X_raw, y_raw, idx_data, idx_bag, classifier, init_size, cost):\n",
    "\n",
    "    from modAL.expected_error import expected_error_reduction\n",
    "    \n",
    "    sample_size = 0 #contador de amostras utilizadas pela estratégia\n",
    "    accuracy_history = []\n",
    "    f1_history = []\n",
    "    start = timer()\n",
    "    \n",
    "    # parte randomica inicial da estratégia\n",
    "    #initial_idx = np.random.choice(range(len(idx_data[idx_bag][TRAIN])), size=init_size, replace=False)\n",
    "    #X_train, y_train = X_raw[idx_data[idx_bag][TRAIN][initial_idx]], y_raw[idx_data[idx_bag][TRAIN][initial_idx]]\n",
    "    #X_pool, y_pool = X_raw[idx_data[idx_bag][TEST]], y_raw[idx_data[idx_bag][TEST]]\n",
    "    \n",
    "    X_train, X_pool, y_train, y_pool = train_test_split(X_raw[idx_data[idx_bag][TRAIN]], y_raw[idx_data[idx_bag][TRAIN]], train_size= len(np.unique(y_raw)) + init_size, stratify = y_raw[idx_data[idx_bag][TRAIN]])\n",
    "    sample_size = sample_size + len(X_train)\n",
    "\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_bag][TEST]], y_raw[idx_data[idx_bag][TEST]]\n",
    "    \n",
    "    learner = ActiveLearner (\n",
    "        estimator = which_classifier(classifier),\n",
    "        X_training = X_train, y_training = y_train\n",
    "    )\n",
    "    accuracy_history.append(learner.score(X_pool, y_pool))\n",
    "    f1_history.append(compute_f1(learner, X_pool, y_pool, \"weighted\"))\n",
    "\n",
    "    total_of_samples = 1\n",
    "    while (total_of_samples != cost):\n",
    "        print(\"\\t Size of X_pool:\", len(X_pool))\n",
    "        exp_error_idx = expected_error_reduction(learner, X_pool, 'binary', n_instances=init_size)\n",
    "\n",
    "        learner.teach(X_pool[exp_error_idx], y_pool[exp_error_idx])\n",
    "        sample_size = sample_size + init_size\n",
    "    \n",
    "        # X_pool = np.delete(X_pool, exp_error_idx, axis=0)\n",
    "        # y_pool = np.delete(y_pool, exp_error_idx)\n",
    "        \n",
    "        accuracy_history.append(learner.score(X_pool, y_pool))\n",
    "        f1_history.append(compute_f1(learner, X_pool, y_pool, \"weighted\"))\n",
    "        \n",
    "        total_of_samples = total_of_samples + 1\n",
    "    \n",
    "    end = timer()\n",
    "    time_elapsed = end - start\n",
    "\n",
    "\n",
    "    return { \"accuracy_history\": accuracy_history,\n",
    "         \"f1_history\": f1_history,\n",
    "         \"auc_history\": \"auc_history[-1]\",\n",
    "         \"package\": \"modAL\",\n",
    "         \"time_elapsed\": time_elapsed,\n",
    "         \"classifier\": classifier,\n",
    "         \"sample_size\": sample_size / len(X_raw),\n",
    "         \"Strategy\": \"Expected Error Reduction\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Model Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_model_change(X_raw, y_raw, idx_data, idx_bag, classifier, init_size, cost):\n",
    "\n",
    "    from modAL.expected_error import expected_error_reduction\n",
    "    sample_size = 0 #contador de amostras utilizadas pela estratégia\n",
    "    accuracy_history = []\n",
    "    f1_history = []\n",
    "    start = timer()\n",
    "    \n",
    "    X_train, X_pool, y_train, y_pool = train_test_split(X_raw[idx_data[idx_bag][TRAIN]], y_raw[idx_data[idx_bag][TRAIN]], train_size= len(np.unique(y_raw)) + init_size, stratify = y_raw[idx_data[idx_bag][TRAIN]])\n",
    "    sample_size = sample_size + len(X_train)\n",
    "\n",
    "    learner = ActiveLearner (\n",
    "        estimator = which_classifier(classifier),\n",
    "        X_training = X_train, y_training = y_train\n",
    "    )\n",
    "    \n",
    "    accuracy_history.append(learner.score(X_pool, y_pool))\n",
    "    f1_history.append(compute_f1(learner, X_pool, y_pool, \"weighted\"))\n",
    "\n",
    "    total_of_samples = 1\n",
    "    while (total_of_samples != cost):\n",
    "         #print(\"\\t Size of X_pool:\", len(X_pool))\n",
    "        exp_error_idx = np.random.choice(range(len(X_pool)), size=init_size, replace=False)\n",
    "        aux = deepcopy(learner)\n",
    "\n",
    "        aux.teach(X_pool[exp_error_idx], y_pool[exp_error_idx])\n",
    "        score_aux = aux.score(X_pool, y_pool)\n",
    "        score_learner = learner.score(X_pool, y_pool)\n",
    "\n",
    "        if score_aux > score_learner:\n",
    "            learner = deepcopy(aux)\n",
    "            sample_size = sample_size + init_size\n",
    "        \n",
    "        X_pool = np.delete(X_pool, exp_error_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, exp_error_idx, axis=0)\n",
    "        \n",
    "        accuracy_history.append(learner.score(X_pool, y_pool))\n",
    "        f1_history.append(compute_f1(learner, X_pool, y_pool, \"weighted\"))\n",
    "\n",
    "        total_of_samples = total_of_samples + 1\n",
    "    \n",
    "    end = timer()\n",
    "    time_elapsed = end - start\n",
    "\n",
    "    return { \"accuracy_history\": accuracy_history,\n",
    "         \"f1_history\": f1_history,\n",
    "         \"auc_history\": \"auc_history[-1]\",\n",
    "         \"package\": \"modAL\",\n",
    "         \"time_elapsed\": time_elapsed,\n",
    "         \"classifier\": classifier,\n",
    "         \"sample_size\": sample_size / len(X_raw),\n",
    "         \"Strategy\": \"Expected Model Change\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyhard Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config(section, filename='strategies.config'):\n",
    "    from configparser import ConfigParser\n",
    "\n",
    "    # create a parser\n",
    "    parser = ConfigParser()\n",
    "    # read config file\n",
    "    parser.read(\"../\" + filename)\n",
    "    # get section, default to postgresql\n",
    "    strategy = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            strategy[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
    "\n",
    "    # transformando texto em bool\n",
    "    strategy['ascending'] = list(map(lambda x: bool(0 if x == \"False\" else 1), strategy['ascending'].split(',')))\n",
    "    strategy['sortby'] = strategy['sortby'].split(',')\n",
    "    \n",
    "    print(strategy)\n",
    "    \n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyhard_strategies(X_raw, y_raw, idx_data, idx_bag, classifier, init_size, cost, strategy):\n",
    "    \n",
    "    from modAL.uncertainty import classifier_uncertainty\n",
    "    \n",
    "    sample_size = 0 #contador de amostras utilizadas pela estratégia\n",
    "    accuracy_history = []\n",
    "    f1_history = []\n",
    "    start = timer()\n",
    "    \n",
    "    strategy = config(strategy)\n",
    "    \n",
    "    # parte randomica inicial da estratégia\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_raw[idx_data[idx_bag][TRAIN]], y_raw[idx_data[idx_bag][TRAIN]], train_size= len(np.unique(y_raw)) + init_size, stratify = y_raw[idx_data[idx_bag][TRAIN]])\n",
    "    \n",
    "    sample_size = sample_size + len(X_train)\n",
    "\n",
    "    learner = ActiveLearner (\n",
    "        estimator= which_classifier(classifier), #cls,\n",
    "        query_strategy=uncertainty_sampling,\n",
    "        X_training = X_train, y_training = y_train # AL AJUSTA O CLASSIFIER \n",
    "    )\n",
    "\n",
    "    accuracy_history.append(learner.score(X_test, y_test))\n",
    "    f1_history.append(compute_f1(learner, X_test, y_test, \"weighted\"))\n",
    "\n",
    "    total_of_samples = 1\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, train_size=0.03)\n",
    "\n",
    "    idx = np.random.choice(range(len(idx_data[idx_bag][TRAIN])), size=init_size, replace=False)\n",
    "    X_train, y_train = X_raw[idx_data[idx_bag][TRAIN][idx]], y_raw[idx_data[idx_bag][TRAIN][idx]]\n",
    "\n",
    "    X_rawAndY_raw = np.column_stack([X_raw[idx_data[idx_bag][TRAIN]],y_raw[idx_data[idx_bag][TRAIN]]])\n",
    "    np.savetxt(\"data.csv\", X_rawAndY_raw, fmt='%i', delimiter=\",\")\n",
    "    \n",
    "    which_pyhard_measure(strategy['measure'])\n",
    "\n",
    "    !pyhard --no-isa\n",
    "\n",
    "    df = pd.read_csv('metadata.csv')\n",
    "\n",
    "    idx = list(df.sort_values(by=strategy['sortby'], ascending=strategy['ascending'])['instances'][:cost])\n",
    "\n",
    "    X_train = X_raw[idx_data[idx_bag][TRAIN][idx]]\n",
    "    y_train = y_raw[idx_data[idx_bag][TRAIN][idx]]\n",
    "\n",
    "    sample_size = cost\n",
    "    learner.teach(X_train, y_train)\n",
    "    \n",
    "    accuracy_history.append(learner.score(X_test, y_test))\n",
    "    f1_history.append(compute_f1(learner, X_test, y_test, \"weighted\"))\n",
    "    \n",
    "    end = timer()\n",
    "    time_elapsed = end - start\n",
    "\n",
    "    return { \"accuracy_history\": accuracy_history,\n",
    "         \"f1_history\": f1_history,\n",
    "         \"auc_history\": \"auc_history[-1]\",\n",
    "         \"package\": \"Pyhard\",\n",
    "         \"time_elapsed\": time_elapsed,\n",
    "         \"classifier\": classifier,\n",
    "         \"sample_size\": sample_size / len(X_raw),\n",
    "         \"Strategy\": strategy['name']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando: 61_iris 5NN 0/5 H+U\n",
      "{'name': 'Lowest H, Highest U Sampling', 'measure': 'U+H', 'sortby': ['feature_Usefulness', 'feature_Harmfulness'], 'ascending': [False, True]}\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/bin/pyhard\", line 5, in <module>\n",
      "    from pyhard.cli import cli\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/pyhard/cli.py\", line 10, in <module>\n",
      "    from pyispace.example import save_opts\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/pyispace/__init__.py\", line 3, in <module>\n",
      "    from .train import train_is\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/pyispace/train.py\", line 11, in <module>\n",
      "    from .trace import TraceOutput, trace\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/pyispace/trace.py\", line 10, in <module>\n",
      "    import alphashape\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/alphashape/__init__.py\", line 10, in <module>\n",
      "    from .optimizealpha import optimizealpha\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/alphashape/optimizealpha.py\", line 6, in <module>\n",
      "    import trimesh\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/trimesh/__init__.py\", line 27, in <module>\n",
      "    from .exchange.load import (\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/trimesh/exchange/load.py\", line 24, in <module>\n",
      "    from .binvox import _binvox_loaders\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "Passou: 61_iris 5NN 0/5 H+U\n",
      "Testando: 61_iris 5NN 1/5 H+U\n",
      "{'name': 'Lowest H, Highest U Sampling', 'measure': 'U+H', 'sortby': ['feature_Usefulness', 'feature_Harmfulness'], 'ascending': [False, True]}\n",
      "Passou: 61_iris 5NN 1/5 H+U\n",
      "Testando: 61_iris 5NN 2/5 H+U\n",
      "{'name': 'Lowest H, Highest U Sampling', 'measure': 'U+H', 'sortby': ['feature_Usefulness', 'feature_Harmfulness'], 'ascending': [False, True]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-791ea12a43b5>\", line 13, in <module>\n",
      "    result = pyhard_strategies(deepcopy(X_raw), deepcopy(y_raw), idx_data, idx_bag, classifier, k, cost, ph_strategy)\n",
      "  File \"<ipython-input-81-8e47be37e8ac>\", line 35, in pyhard_strategies\n",
      "    np.savetxt(\"data.csv\", X_rawAndY_raw, fmt='%i', delimiter=\",\")\n",
      "  File \"<__array_function__ internals>\", line 6, in savetxt\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 1367, in savetxt\n",
      "    fh = np.lib._datasource.open(fname, 'wt', encoding=encoding)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 194, in open\n",
      "    return ds.open(path, mode, encoding=encoding, newline=newline)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 523, in open\n",
      "    found = self._findfile(path)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 367, in _findfile\n",
      "    if self.exists(name):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 461, in exists\n",
      "    if os.path.exists(path):\n",
      "  File \"/usr/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/usr/lib/python3.7/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/usr/lib/python3.7/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/usr/lib/python3.7/tokenize.py\", line 447, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-791ea12a43b5>\", line 13, in <module>\n",
      "    result = pyhard_strategies(deepcopy(X_raw), deepcopy(y_raw), idx_data, idx_bag, classifier, k, cost, ph_strategy)\n",
      "  File \"<ipython-input-81-8e47be37e8ac>\", line 35, in pyhard_strategies\n",
      "    np.savetxt(\"data.csv\", X_rawAndY_raw, fmt='%i', delimiter=\",\")\n",
      "  File \"<__array_function__ internals>\", line 6, in savetxt\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 1367, in savetxt\n",
      "    fh = np.lib._datasource.open(fname, 'wt', encoding=encoding)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 194, in open\n",
      "    return ds.open(path, mode, encoding=encoding, newline=newline)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 523, in open\n",
      "    found = self._findfile(path)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 367, in _findfile\n",
      "    if self.exists(name):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 461, in exists\n",
      "    if os.path.exists(path):\n",
      "  File \"/usr/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3454, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/usr/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-791ea12a43b5>\", line 13, in <module>\n",
      "    result = pyhard_strategies(deepcopy(X_raw), deepcopy(y_raw), idx_data, idx_bag, classifier, k, cost, ph_strategy)\n",
      "  File \"<ipython-input-81-8e47be37e8ac>\", line 35, in pyhard_strategies\n",
      "    np.savetxt(\"data.csv\", X_rawAndY_raw, fmt='%i', delimiter=\",\")\n",
      "  File \"<__array_function__ internals>\", line 6, in savetxt\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 1367, in savetxt\n",
      "    fh = np.lib._datasource.open(fname, 'wt', encoding=encoding)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 194, in open\n",
      "    return ds.open(path, mode, encoding=encoding, newline=newline)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 523, in open\n",
      "    found = self._findfile(path)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 367, in _findfile\n",
      "    if self.exists(name):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/numpy/lib/_datasource.py\", line 461, in exists\n",
      "    if os.path.exists(path):\n",
      "  File \"/usr/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3454, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3166, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3376, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_performance_history = []\n",
    "#pyhard_strategies_names = ['H','U','H+U','LSC','N2','F3']\n",
    "\n",
    "pyhard_strategies_names = ['H+U']\n",
    "\n",
    "for ds in datasets:\n",
    "    for classifier in classifiers:\n",
    "        X_raw, y_raw, idx_data, dataset_name = which_arff_dataset(ds)\n",
    "        #para cada i em idx_bag (\"n_splits\") (1 a 5)\n",
    "        for idx_bag in range(n_splits):\n",
    "            for ph_strategy in pyhard_strategies_names:\n",
    "                tqdm.write(\"Testando: \" + str(ds[:-5]) + \" \" + str(classifier) + \" \" + str(idx_bag) + \"/\" + str(n_splits) + \" \" + ph_strategy)\n",
    "                result = pyhard_strategies(deepcopy(X_raw), deepcopy(y_raw), idx_data, idx_bag, classifier, k, cost, ph_strategy)\n",
    "                result['dataset'] = ds[:-5]\n",
    "                total_performance_history.append(result)\n",
    "                tqdm.write(\"Passou: \" + str(ds[:-5]) + \" \" + str(classifier) + \" \" + str(idx_bag) + \"/\" + str(n_splits) + \" \" + ph_strategy)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accuracy_history': [0.7010309278350515, 0.8865979381443299],\n",
       "  'f1_history': [0.6244144858577848, 0.8818721677250521],\n",
       "  'auc_history': 'auc_history[-1]',\n",
       "  'package': 'Pyhard',\n",
       "  'time_elapsed': 60.12400930000149,\n",
       "  'classifier': '5NN',\n",
       "  'sample_size': 0.06666666666666667,\n",
       "  'Strategy': 'Lowest H, Highest U Sampling',\n",
       "  'dataset': '61_iris'},\n",
       " {'accuracy_history': [0.8144329896907216, 0.9175257731958762],\n",
       "  'f1_history': [0.796328237209154, 0.9152484997691952],\n",
       "  'auc_history': 'auc_history[-1]',\n",
       "  'package': 'Pyhard',\n",
       "  'time_elapsed': 20.384290000001783,\n",
       "  'classifier': '5NN',\n",
       "  'sample_size': 0.06666666666666667,\n",
       "  'Strategy': 'Lowest H, Highest U Sampling',\n",
       "  'dataset': '61_iris'}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 22\n"
     ]
    }
   ],
   "source": [
    "total_performance_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_pyhard_measure(measure='LSC'):\n",
    "    import yaml\n",
    "    with open(r'config-template.yaml') as file:\n",
    "        configs_list = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "        if measure == 'LSC':\n",
    "            configs_list['measures_list'] = ['LSC']\n",
    "        elif measure == 'Harmfulness':\n",
    "            configs_list['measures_list'] = ['Harmfulness']\n",
    "        elif measure == 'Usefulness':\n",
    "            configs_list['measures_list'] = ['Usefulness']\n",
    "        elif measure == 'U+H':\n",
    "            configs_list['measures_list'] = ['Harmfulness','Usefulness']\n",
    "        elif measure == 'N2':\n",
    "            configs_list['measures_list'] = ['N2']\n",
    "        elif measure == 'F3':\n",
    "            configs_list['measures_list'] = ['F3']\n",
    "\n",
    "    with open(r'config.yaml', 'w') as file:\n",
    "        yaml.dump(configs_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_dataset(dataset = \"iris\", n_splits = 5):\n",
    "    \n",
    "    # Futuramente essa etapa será ajustada para receber qualquer dataset (ou lista com datasets)\n",
    "    if (dataset == \"iris\"):\n",
    "        data = load_iris()\n",
    "        X_raw = data['data']\n",
    "        y_raw = data['target']\n",
    "    \n",
    "    if (dataset == \"wine\"):\n",
    "        data = load_wine()\n",
    "        X_raw = data['data']\n",
    "        y_raw = data['target']\n",
    "        \n",
    "    if (dataset == \"digits\"):\n",
    "        data = load_digits()\n",
    "        X_raw = data['data']\n",
    "        y_raw = data['target']\n",
    "        \n",
    "    # cross validation bags\n",
    "    data_cv = StratifiedShuffleSplit(n_splits= n_splits, train_size=0.7, random_state=0) #n_splits\n",
    "    \n",
    "    # extraindo ids do data_cv\n",
    "    idx_data = []\n",
    "    for train_index, test_index in data_cv.split(X_raw):\n",
    "            idx_data.append([train_index, test_index])\n",
    "\n",
    "    return X_raw, y_raw, idx_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_oml_dataset(dataset_id, n_splits = 5):\n",
    "    data = openml.datasets.get_dataset(dataset_id)\n",
    "    \n",
    "    X_raw, y_raw, categorical_indicator, attribute_names = data.get_data(\n",
    "    dataset_format=\"array\", target=data.default_target_attribute)\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y_raw)\n",
    "    y_raw = le.transform(y_raw)\n",
    "    \n",
    "    X_raw = np.nan_to_num(X_raw)\n",
    "    \n",
    "    data_cv = StratifiedShuffleSplit(n_splits= n_splits, train_size=0.7, random_state=0) #n_splits\n",
    "    \n",
    "    idx_data = []\n",
    "    for train_index, test_index in data_cv.split(X_raw):\n",
    "            idx_data.append([train_index, test_index])\n",
    "\n",
    "    return X_raw, y_raw, idx_data, data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_arff_dataset(dataset, n_splits = 5):\n",
    "   \n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    \n",
    "    data = arff.loadarff('datasets/luis/' + dataset)\n",
    "    data = pd.DataFrame(data[0])\n",
    "\n",
    "    X_raw = data[data.columns[:-1]].to_numpy()\n",
    "    y_raw = data[data.columns[-1]].to_numpy()\n",
    "    \n",
    "    lex = preprocessing.OrdinalEncoder()\n",
    "    lex.fit(X_raw)\n",
    "    X_raw = lex.transform(X_raw)\n",
    "        \n",
    "    ley = preprocessing.LabelEncoder()\n",
    "    ley.fit(y_raw)\n",
    "    y_raw = ley.transform(y_raw)\n",
    "    \n",
    "    # cross validation bags\n",
    "    data_cv = StratifiedShuffleSplit(n_splits= n_splits, train_size=0.7, random_state=0) #n_splits\n",
    "    data_cv.get_n_splits(X_raw,y_raw)\n",
    "    \n",
    "    # extraindo ids do data_cv\n",
    "    idx_data = []\n",
    "    for train_index, test_index in data_cv.split(X_raw, y_raw):\n",
    "            idx_data.append([train_index, test_index])\n",
    "\n",
    "    return X_raw, y_raw, idx_data, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_classifier(classifier = '5NN'):\n",
    "    \n",
    "    if (classifier == '5NN'):\n",
    "        return KNeighborsClassifier(5)\n",
    "    elif (classifier == 'C4.5'):\n",
    "        return tree.DecisionTreeClassifier()\n",
    "    elif (classifier == 'NB'):\n",
    "        return GaussianNB()\n",
    "    elif (classifier == 'SVM'):\n",
    "        return SVC(probability=True, gamma='auto')\n",
    "    elif (classifier == 'RF'):\n",
    "        return RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_datasets(dataset):\n",
    "    \n",
    "    data = arff.loadarff('./datasets/luis/' + dataset)\n",
    "    metadata = data[1]\n",
    "    data = pd.DataFrame(data[0])\n",
    "    \n",
    "    instances = len(data)\n",
    "    classes = len(data.iloc[:,-1].value_counts())\n",
    "    attributes = len(data.columns)- 1\n",
    "    nominal_attributes = str(metadata).count(\"nominal\")\n",
    "    \n",
    "    proportion = data.iloc[:,-1].value_counts()\n",
    "    proportion = proportion.map(lambda x: round(x/instances*100,2))\n",
    "\n",
    "    majority = max(proportion)\n",
    "    minority = min(proportion)\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"name\": dataset[:-5],\n",
    "        \"instances\": instances,\n",
    "        \"classes\": classes,\n",
    "        \"attributes\": attributes,\n",
    "        \"nominal attributes\": nominal_attributes,\n",
    "        \"majority\": majority,\n",
    "        \"minority\": minority\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = os.listdir('./datasets/luis')\n",
    "classifiers = ['5NN', 'C4.5', 'NB','RF']\n",
    "total_performance_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['61_iris.arff']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>instances</th>\n",
       "      <th>classes</th>\n",
       "      <th>attributes</th>\n",
       "      <th>nominal attributes</th>\n",
       "      <th>majority</th>\n",
       "      <th>minority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61_iris</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>33.33</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  instances  classes  attributes  nominal attributes  majority  \\\n",
       "0  61_iris        150        3           4                   1     33.33   \n",
       "\n",
       "   minority  \n",
       "0     33.33  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = []\n",
    "\n",
    "for ds in datasets:\n",
    "    metadata.append(fetch_datasets(ds))\n",
    "\n",
    "metadata = pd.DataFrame.from_dict(metadata)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando: 61_iris 5NN 0/5 H\n",
      "{'name': 'Lowest Harmfulness Sampling', 'measure': 'Harmfulness', 'sortby': ['feature_Harmfulness'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:46:28,351 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:46:28,355 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:46:28,372 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:46:28,373 - Building metadata.\n",
      "[INFO] 2021-04-27 18:46:33,762 - Calculating measure 'Harmfulness'\n",
      "[INFO] 2021-04-27 18:46:33,783 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:46:33,783 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:46:33,785 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:46:34,638 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 18:46:34,639 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 18:46:35,331 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:46:35,331 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:46:35,332 - Mean accuracy on test instances (iteration #1): 0.9519\n",
      "[INFO] 2021-04-27 18:46:35,384 - Total elapsed time: 7.1s\n",
      "[INFO] 2021-04-27 18:46:35,385 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 0/5 H\n",
      "Testando: 61_iris 5NN 0/5 U\n",
      "{'name': 'Highest Usefulness Sampling', 'measure': 'Usefulness', 'sortby': ['feature_Usefulness'], 'ascending': [False]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:47:18,016 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:47:18,020 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:47:18,029 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:47:18,029 - Building metadata.\n",
      "[INFO] 2021-04-27 18:47:22,851 - Calculating measure 'Usefulness'\n",
      "[INFO] 2021-04-27 18:47:22,855 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:47:22,855 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:47:22,856 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:47:23,654 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 18:47:23,654 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 18:47:24,438 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:47:24,438 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:47:24,439 - Mean accuracy on test instances (iteration #1): 0.9519\n",
      "[INFO] 2021-04-27 18:47:24,494 - Total elapsed time: 6.5s\n",
      "[INFO] 2021-04-27 18:47:24,494 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 0/5 U\n",
      "Testando: 61_iris 5NN 0/5 H+U\n",
      "{'name': 'Lowest H, Highest U Sampling', 'measure': 'U+H', 'sortby': ['feature_Usefulness', 'feature_Harmfulness'], 'ascending': [False, True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:48:17,136 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:48:17,143 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:48:17,155 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:48:17,155 - Building metadata.\n",
      "[INFO] 2021-04-27 18:48:22,320 - Calculating measure 'Usefulness'\n",
      "[INFO] 2021-04-27 18:48:22,322 - Calculating measure 'Harmfulness'\n",
      "[INFO] 2021-04-27 18:48:22,326 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:48:22,326 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:48:22,327 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:48:23,180 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 18:48:23,180 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 18:48:24,003 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:48:24,004 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:48:24,005 - Mean accuracy on test instances (iteration #1): 0.9519\n",
      "[INFO] 2021-04-27 18:48:24,125 - Total elapsed time: 7.0s\n",
      "[INFO] 2021-04-27 18:48:24,126 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 0/5 H+U\n",
      "Testando: 61_iris 5NN 0/5 LSC\n",
      "{'name': 'Highest LSC Sampling', 'measure': 'LSC', 'sortby': ['feature_LSC'], 'ascending': [False]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:49:10,014 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:49:10,021 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:49:10,032 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:49:10,032 - Building metadata.\n",
      "[INFO] 2021-04-27 18:49:15,295 - Calculating measure 'LSC'\n",
      "[INFO] 2021-04-27 18:49:15,416 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:49:15,417 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:49:15,419 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:49:16,264 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 18:49:16,264 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 18:49:17,062 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:49:17,062 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:49:17,063 - Mean accuracy on test instances (iteration #1): 0.9519\n",
      "[INFO] 2021-04-27 18:49:17,125 - Total elapsed time: 7.1s\n",
      "[INFO] 2021-04-27 18:49:17,125 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 0/5 LSC\n",
      "Testando: 61_iris 5NN 0/5 N2\n",
      "{'name': 'Lowest N2 Sampling', 'measure': 'N2', 'sortby': ['feature_N2'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:50:17,585 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:50:17,593 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:50:17,604 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:50:17,605 - Building metadata.\n",
      "[INFO] 2021-04-27 18:50:23,229 - Calculating measure 'N2'\n",
      "[INFO] 2021-04-27 18:50:23,598 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:50:23,598 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:50:23,600 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:50:24,490 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 18:50:24,490 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 18:50:25,305 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:50:25,306 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:50:25,308 - Mean accuracy on test instances (iteration #1): 0.9519\n",
      "[INFO] 2021-04-27 18:50:25,366 - Total elapsed time: 7.8s\n",
      "[INFO] 2021-04-27 18:50:25,367 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 0/5 N2\n",
      "Testando: 61_iris 5NN 0/5 F3\n",
      "{'name': 'Lowest F3 Sampling', 'measure': 'F3', 'sortby': ['feature_F3'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:51:10,951 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:51:10,957 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:51:10,974 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:51:10,975 - Building metadata.\n",
      "[INFO] 2021-04-27 18:51:16,052 - Calculating measure 'F3'\n",
      "[INFO] 2021-04-27 18:51:16,235 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:51:16,235 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:51:16,237 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:51:17,070 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 18:51:17,070 - Evaluating testing fold #2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2021-04-27 18:51:17,870 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:51:17,870 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:51:17,870 - Mean accuracy on test instances (iteration #1): 0.9519\n",
      "[INFO] 2021-04-27 18:51:17,925 - Total elapsed time: 7.0s\n",
      "[INFO] 2021-04-27 18:51:17,925 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 0/5 F3\n",
      "Testando: 61_iris 5NN 1/5 H\n",
      "{'name': 'Lowest Harmfulness Sampling', 'measure': 'Harmfulness', 'sortby': ['feature_Harmfulness'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:52:19,679 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:52:19,685 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:52:19,697 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:52:19,697 - Building metadata.\n",
      "[INFO] 2021-04-27 18:52:25,973 - Calculating measure 'Harmfulness'\n",
      "[INFO] 2021-04-27 18:52:25,979 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:52:25,980 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:52:25,981 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:52:27,029 - Test fold mean accuracy: 0.9807692307692307\n",
      "[INFO] 2021-04-27 18:52:27,029 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 18:52:28,070 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:52:28,071 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:52:28,075 - Mean accuracy on test instances (iteration #1): 0.9615\n",
      "[INFO] 2021-04-27 18:52:28,169 - Total elapsed time: 8.5s\n",
      "[INFO] 2021-04-27 18:52:28,169 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 1/5 H\n",
      "Testando: 61_iris 5NN 1/5 U\n",
      "{'name': 'Highest Usefulness Sampling', 'measure': 'Usefulness', 'sortby': ['feature_Usefulness'], 'ascending': [False]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:53:17,768 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:53:17,775 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:53:17,787 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:53:17,787 - Building metadata.\n",
      "[INFO] 2021-04-27 18:53:22,976 - Calculating measure 'Usefulness'\n",
      "[INFO] 2021-04-27 18:53:22,984 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:53:22,984 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:53:22,986 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:53:23,790 - Test fold mean accuracy: 0.9807692307692307\n",
      "[INFO] 2021-04-27 18:53:23,791 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 18:53:24,610 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:53:24,610 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:53:24,611 - Mean accuracy on test instances (iteration #1): 0.9615\n",
      "[INFO] 2021-04-27 18:53:24,659 - Total elapsed time: 6.9s\n",
      "[INFO] 2021-04-27 18:53:24,660 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 1/5 U\n",
      "Testando: 61_iris 5NN 1/5 H+U\n",
      "{'name': 'Lowest H, Highest U Sampling', 'measure': 'U+H', 'sortby': ['feature_Usefulness', 'feature_Harmfulness'], 'ascending': [False, True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:54:32,081 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:54:32,090 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:54:32,110 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:54:32,113 - Building metadata.\n",
      "[INFO] 2021-04-27 18:54:37,424 - Calculating measure 'Usefulness'\n",
      "[INFO] 2021-04-27 18:54:37,430 - Calculating measure 'Harmfulness'\n",
      "[INFO] 2021-04-27 18:54:37,435 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:54:37,436 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:54:37,439 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:54:38,247 - Test fold mean accuracy: 0.9807692307692307\n",
      "[INFO] 2021-04-27 18:54:38,247 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 18:54:38,928 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:54:38,928 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:54:38,929 - Mean accuracy on test instances (iteration #1): 0.9615\n",
      "[INFO] 2021-04-27 18:54:38,996 - Total elapsed time: 7.0s\n",
      "[INFO] 2021-04-27 18:54:38,996 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 1/5 H+U\n",
      "Testando: 61_iris 5NN 1/5 LSC\n",
      "{'name': 'Highest LSC Sampling', 'measure': 'LSC', 'sortby': ['feature_LSC'], 'ascending': [False]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:55:36,969 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:55:36,979 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:55:37,008 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:55:37,009 - Building metadata.\n",
      "[INFO] 2021-04-27 18:55:44,939 - Calculating measure 'LSC'\n",
      "[INFO] 2021-04-27 18:55:45,062 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:55:45,062 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:55:45,064 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:55:46,304 - Test fold mean accuracy: 0.9807692307692307\n",
      "[INFO] 2021-04-27 18:55:46,304 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 18:55:47,515 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:55:47,516 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:55:47,517 - Mean accuracy on test instances (iteration #1): 0.9615\n",
      "[INFO] 2021-04-27 18:55:47,608 - Total elapsed time: 10.7s\n",
      "[INFO] 2021-04-27 18:55:47,608 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 1/5 LSC\n",
      "Testando: 61_iris 5NN 1/5 N2\n",
      "{'name': 'Lowest N2 Sampling', 'measure': 'N2', 'sortby': ['feature_N2'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:56:53,482 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:56:53,489 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:56:53,501 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:56:53,501 - Building metadata.\n",
      "[INFO] 2021-04-27 18:57:03,133 - Calculating measure 'N2'\n",
      "[INFO] 2021-04-27 18:57:03,494 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:57:03,494 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:57:03,496 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:57:04,568 - Test fold mean accuracy: 0.9807692307692307\n",
      "[INFO] 2021-04-27 18:57:04,568 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 18:57:05,571 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:57:05,571 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:57:05,573 - Mean accuracy on test instances (iteration #1): 0.9615\n",
      "[INFO] 2021-04-27 18:57:05,659 - Total elapsed time: 12.2s\n",
      "[INFO] 2021-04-27 18:57:05,659 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 1/5 N2\n",
      "Testando: 61_iris 5NN 1/5 F3\n",
      "{'name': 'Lowest F3 Sampling', 'measure': 'F3', 'sortby': ['feature_F3'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:58:14,389 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:58:14,393 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:58:14,404 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:58:14,404 - Building metadata.\n",
      "[INFO] 2021-04-27 18:58:19,575 - Calculating measure 'F3'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2021-04-27 18:58:19,673 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:58:19,673 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:58:19,674 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:58:20,491 - Test fold mean accuracy: 0.9807692307692307\n",
      "[INFO] 2021-04-27 18:58:20,492 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 18:58:21,801 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:58:21,801 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:58:21,802 - Mean accuracy on test instances (iteration #1): 0.9615\n",
      "[INFO] 2021-04-27 18:58:21,893 - Total elapsed time: 7.5s\n",
      "[INFO] 2021-04-27 18:58:21,893 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 1/5 F3\n",
      "Testando: 61_iris 5NN 2/5 H\n",
      "{'name': 'Lowest Harmfulness Sampling', 'measure': 'Harmfulness', 'sortby': ['feature_Harmfulness'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 18:59:26,768 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 18:59:26,779 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 18:59:26,794 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 18:59:26,794 - Building metadata.\n",
      "[INFO] 2021-04-27 18:59:34,643 - Calculating measure 'Harmfulness'\n",
      "[INFO] 2021-04-27 18:59:34,649 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 18:59:34,650 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 18:59:34,652 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 18:59:35,716 - Test fold mean accuracy: 0.9230769230769231\n",
      "[INFO] 2021-04-27 18:59:35,716 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 18:59:36,861 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 18:59:36,861 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 18:59:36,862 - Mean accuracy on test instances (iteration #1): 0.9327\n",
      "[INFO] 2021-04-27 18:59:36,924 - Total elapsed time: 10.2s\n",
      "[INFO] 2021-04-27 18:59:36,925 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 2/5 H\n",
      "Testando: 61_iris 5NN 2/5 U\n",
      "{'name': 'Highest Usefulness Sampling', 'measure': 'Usefulness', 'sortby': ['feature_Usefulness'], 'ascending': [False]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:00:41,525 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:00:41,532 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:00:41,553 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:00:41,554 - Building metadata.\n",
      "[INFO] 2021-04-27 19:00:48,297 - Calculating measure 'Usefulness'\n",
      "[INFO] 2021-04-27 19:00:48,301 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:00:48,301 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:00:48,302 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:00:49,118 - Test fold mean accuracy: 0.9230769230769231\n",
      "[INFO] 2021-04-27 19:00:49,118 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:00:49,907 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 19:00:49,908 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:00:49,908 - Mean accuracy on test instances (iteration #1): 0.9327\n",
      "[INFO] 2021-04-27 19:00:49,960 - Total elapsed time: 8.5s\n",
      "[INFO] 2021-04-27 19:00:49,960 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 2/5 U\n",
      "Testando: 61_iris 5NN 2/5 H+U\n",
      "{'name': 'Lowest H, Highest U Sampling', 'measure': 'U+H', 'sortby': ['feature_Usefulness', 'feature_Harmfulness'], 'ascending': [False, True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:01:51,731 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:01:51,744 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:01:51,774 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:01:51,774 - Building metadata.\n",
      "[INFO] 2021-04-27 19:02:00,768 - Calculating measure 'Usefulness'\n",
      "[INFO] 2021-04-27 19:02:00,774 - Calculating measure 'Harmfulness'\n",
      "[INFO] 2021-04-27 19:02:00,791 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:02:00,792 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:02:00,804 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:02:01,900 - Test fold mean accuracy: 0.9230769230769231\n",
      "[INFO] 2021-04-27 19:02:01,901 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:02:02,975 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 19:02:02,975 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:02:02,976 - Mean accuracy on test instances (iteration #1): 0.9327\n",
      "[INFO] 2021-04-27 19:02:03,036 - Total elapsed time: 11.4s\n",
      "[INFO] 2021-04-27 19:02:03,037 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 2/5 H+U\n",
      "Testando: 61_iris 5NN 2/5 LSC\n",
      "{'name': 'Highest LSC Sampling', 'measure': 'LSC', 'sortby': ['feature_LSC'], 'ascending': [False]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:03:19,144 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:03:19,150 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:03:19,159 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:03:19,159 - Building metadata.\n",
      "[INFO] 2021-04-27 19:03:32,532 - Calculating measure 'LSC'\n",
      "[INFO] 2021-04-27 19:03:32,657 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:03:32,657 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:03:32,659 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:03:33,636 - Test fold mean accuracy: 0.9230769230769231\n",
      "[INFO] 2021-04-27 19:03:33,636 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:03:34,622 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 19:03:34,622 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:03:34,623 - Mean accuracy on test instances (iteration #1): 0.9327\n",
      "[INFO] 2021-04-27 19:03:34,733 - Total elapsed time: 15.6s\n",
      "[INFO] 2021-04-27 19:03:34,733 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 2/5 LSC\n",
      "Testando: 61_iris 5NN 2/5 N2\n",
      "{'name': 'Lowest N2 Sampling', 'measure': 'N2', 'sortby': ['feature_N2'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:04:40,511 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:04:40,519 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:04:40,532 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:04:40,532 - Building metadata.\n",
      "[INFO] 2021-04-27 19:04:49,123 - Calculating measure 'N2'\n",
      "[INFO] 2021-04-27 19:04:49,533 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:04:49,533 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:04:49,535 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:04:50,528 - Test fold mean accuracy: 0.9230769230769231\n",
      "[INFO] 2021-04-27 19:04:50,529 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:04:51,355 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 19:04:51,355 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:04:51,356 - Mean accuracy on test instances (iteration #1): 0.9327\n",
      "[INFO] 2021-04-27 19:04:51,406 - Total elapsed time: 10.9s\n",
      "[INFO] 2021-04-27 19:04:51,406 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 2/5 N2\n",
      "Testando: 61_iris 5NN 2/5 F3\n",
      "{'name': 'Lowest F3 Sampling', 'measure': 'F3', 'sortby': ['feature_F3'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:06:00,457 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:06:00,462 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:06:00,472 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:06:00,472 - Building metadata.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2021-04-27 19:06:08,949 - Calculating measure 'F3'\n",
      "[INFO] 2021-04-27 19:06:09,076 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:06:09,076 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:06:09,078 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:06:10,082 - Test fold mean accuracy: 0.9230769230769231\n",
      "[INFO] 2021-04-27 19:06:10,082 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:06:11,069 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 19:06:11,069 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:06:11,070 - Mean accuracy on test instances (iteration #1): 0.9327\n",
      "[INFO] 2021-04-27 19:06:11,132 - Total elapsed time: 10.7s\n",
      "[INFO] 2021-04-27 19:06:11,132 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 2/5 F3\n",
      "Testando: 61_iris 5NN 3/5 H\n",
      "{'name': 'Lowest Harmfulness Sampling', 'measure': 'Harmfulness', 'sortby': ['feature_Harmfulness'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:07:01,268 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:07:01,278 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:07:01,303 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:07:01,304 - Building metadata.\n",
      "[INFO] 2021-04-27 19:07:07,400 - Calculating measure 'Harmfulness'\n",
      "[INFO] 2021-04-27 19:07:07,406 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:07:07,408 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:07:07,411 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:07:08,335 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 19:07:08,335 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:07:09,144 - Test fold mean accuracy: 0.9038461538461539\n",
      "[INFO] 2021-04-27 19:07:09,144 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:07:09,144 - Mean accuracy on test instances (iteration #1): 0.9327\n",
      "[INFO] 2021-04-27 19:07:09,213 - Total elapsed time: 8.0s\n",
      "[INFO] 2021-04-27 19:07:09,213 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 3/5 H\n",
      "Testando: 61_iris 5NN 3/5 U\n",
      "{'name': 'Highest Usefulness Sampling', 'measure': 'Usefulness', 'sortby': ['feature_Usefulness'], 'ascending': [False]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:08:14,400 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:08:14,406 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:08:14,420 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:08:14,421 - Building metadata.\n",
      "[INFO] 2021-04-27 19:08:19,324 - Calculating measure 'Usefulness'\n",
      "[INFO] 2021-04-27 19:08:19,329 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:08:19,329 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:08:19,330 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:08:20,032 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 19:08:20,033 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:08:20,732 - Test fold mean accuracy: 0.9038461538461539\n",
      "[INFO] 2021-04-27 19:08:20,732 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:08:20,733 - Mean accuracy on test instances (iteration #1): 0.9327\n",
      "[INFO] 2021-04-27 19:08:20,778 - Total elapsed time: 6.4s\n",
      "[INFO] 2021-04-27 19:08:20,778 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 3/5 U\n",
      "Testando: 61_iris 5NN 3/5 H+U\n",
      "{'name': 'Lowest H, Highest U Sampling', 'measure': 'U+H', 'sortby': ['feature_Usefulness', 'feature_Harmfulness'], 'ascending': [False, True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:09:18,534 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:09:18,538 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:09:18,547 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:09:18,548 - Building metadata.\n",
      "[INFO] 2021-04-27 19:09:26,054 - Calculating measure 'Usefulness'\n",
      "[INFO] 2021-04-27 19:09:26,058 - Calculating measure 'Harmfulness'\n",
      "[INFO] 2021-04-27 19:09:26,066 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:09:26,069 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:09:26,071 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:09:27,048 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 19:09:27,048 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:09:28,009 - Test fold mean accuracy: 0.9038461538461539\n",
      "[INFO] 2021-04-27 19:09:28,009 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:09:28,010 - Mean accuracy on test instances (iteration #1): 0.9327\n",
      "[INFO] 2021-04-27 19:09:28,083 - Total elapsed time: 9.6s\n",
      "[INFO] 2021-04-27 19:09:28,083 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 3/5 H+U\n",
      "Testando: 61_iris 5NN 3/5 LSC\n",
      "{'name': 'Highest LSC Sampling', 'measure': 'LSC', 'sortby': ['feature_LSC'], 'ascending': [False]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:10:26,970 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:10:26,976 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:10:26,994 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:10:26,994 - Building metadata.\n",
      "[INFO] 2021-04-27 19:10:32,704 - Calculating measure 'LSC'\n",
      "[INFO] 2021-04-27 19:10:32,845 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:10:32,846 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:10:32,847 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:10:33,930 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 19:10:33,930 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:10:35,187 - Test fold mean accuracy: 0.9038461538461539\n",
      "[INFO] 2021-04-27 19:10:35,188 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:10:35,189 - Mean accuracy on test instances (iteration #1): 0.9327\n",
      "[INFO] 2021-04-27 19:10:35,271 - Total elapsed time: 8.3s\n",
      "[INFO] 2021-04-27 19:10:35,271 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 3/5 LSC\n",
      "Testando: 61_iris 5NN 3/5 N2\n",
      "{'name': 'Lowest N2 Sampling', 'measure': 'N2', 'sortby': ['feature_N2'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:11:31,351 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:11:31,358 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:11:31,385 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:11:31,387 - Building metadata.\n",
      "[INFO] 2021-04-27 19:11:40,581 - Calculating measure 'N2'\n",
      "[INFO] 2021-04-27 19:11:40,922 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:11:40,923 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:11:40,924 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:11:41,919 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 19:11:41,920 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:11:42,899 - Test fold mean accuracy: 0.9038461538461539\n",
      "[INFO] 2021-04-27 19:11:42,899 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:11:42,900 - Mean accuracy on test instances (iteration #1): 0.9327\n",
      "[INFO] 2021-04-27 19:11:43,036 - Total elapsed time: 11.7s\n",
      "[INFO] 2021-04-27 19:11:43,036 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 3/5 N2\n",
      "Testando: 61_iris 5NN 3/5 F3\n",
      "{'name': 'Lowest F3 Sampling', 'measure': 'F3', 'sortby': ['feature_F3'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:12:46,455 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2021-04-27 19:12:46,471 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:12:46,490 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:12:46,490 - Building metadata.\n",
      "[INFO] 2021-04-27 19:13:01,117 - Calculating measure 'F3'\n",
      "[INFO] 2021-04-27 19:13:01,378 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:13:01,379 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:13:01,380 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:13:02,379 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 19:13:02,379 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:13:03,344 - Test fold mean accuracy: 0.9038461538461539\n",
      "[INFO] 2021-04-27 19:13:03,344 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:13:03,345 - Mean accuracy on test instances (iteration #1): 0.9327\n",
      "[INFO] 2021-04-27 19:13:03,419 - Total elapsed time: 17.0s\n",
      "[INFO] 2021-04-27 19:13:03,420 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 3/5 F3\n",
      "Testando: 61_iris 5NN 4/5 H\n",
      "{'name': 'Lowest Harmfulness Sampling', 'measure': 'Harmfulness', 'sortby': ['feature_Harmfulness'], 'ascending': [True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:14:49,927 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:14:49,937 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:14:49,959 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:14:49,959 - Building metadata.\n",
      "[INFO] 2021-04-27 19:15:02,230 - Calculating measure 'Harmfulness'\n",
      "[INFO] 2021-04-27 19:15:02,242 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:15:02,242 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:15:02,245 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:15:03,296 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 19:15:03,296 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:15:04,588 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 19:15:04,588 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:15:04,589 - Mean accuracy on test instances (iteration #1): 0.9519\n",
      "[INFO] 2021-04-27 19:15:04,677 - Total elapsed time: 14.8s\n",
      "[INFO] 2021-04-27 19:15:04,677 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 4/5 H\n",
      "Testando: 61_iris 5NN 4/5 U\n",
      "{'name': 'Highest Usefulness Sampling', 'measure': 'Usefulness', 'sortby': ['feature_Usefulness'], 'ascending': [False]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:16:23,403 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:16:23,410 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:16:23,447 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:16:23,448 - Building metadata.\n",
      "[INFO] 2021-04-27 19:16:33,250 - Calculating measure 'Usefulness'\n",
      "[INFO] 2021-04-27 19:16:33,254 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:16:33,254 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:16:33,255 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:16:34,049 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 19:16:34,049 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:16:34,741 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 19:16:34,741 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:16:34,741 - Mean accuracy on test instances (iteration #1): 0.9519\n",
      "[INFO] 2021-04-27 19:16:34,786 - Total elapsed time: 11.4s\n",
      "[INFO] 2021-04-27 19:16:34,786 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 4/5 U\n",
      "Testando: 61_iris 5NN 4/5 H+U\n",
      "{'name': 'Lowest H, Highest U Sampling', 'measure': 'U+H', 'sortby': ['feature_Usefulness', 'feature_Harmfulness'], 'ascending': [False, True]}\n",
      "run 'pyhard --help' to see all options.\n",
      "[INFO] 2021-04-27 19:17:55,149 - Configuration file: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/config.yaml'\n",
      "[INFO] 2021-04-27 19:17:55,161 - Reading input dataset: '/mnt/c/Users/ahmou/OneDrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/data.csv'\n",
      "[INFO] 2021-04-27 19:17:55,187 - Type of problem: 'classification'\n",
      "[INFO] 2021-04-27 19:17:55,187 - Building metadata.\n",
      "[INFO] 2021-04-27 19:18:07,192 - Calculating measure 'Harmfulness'\n",
      "[INFO] 2021-04-27 19:18:07,196 - Calculating measure 'Usefulness'\n",
      "[INFO] 2021-04-27 19:18:07,207 - Assessing performance of classifier 'random_forest'\n",
      "[INFO] 2021-04-27 19:18:07,207 - Estimating instance performance...\n",
      "[INFO] 2021-04-27 19:18:07,213 - Evaluating testing fold #1\n",
      "[INFO] 2021-04-27 19:18:08,271 - Test fold mean accuracy: 0.9423076923076923\n",
      "[INFO] 2021-04-27 19:18:08,272 - Evaluating testing fold #2\n",
      "[INFO] 2021-04-27 19:18:09,280 - Test fold mean accuracy: 0.9615384615384616\n",
      "[INFO] 2021-04-27 19:18:09,283 - Iteration 1/1 completed.\n",
      "[INFO] 2021-04-27 19:18:09,284 - Mean accuracy on test instances (iteration #1): 0.9519\n",
      "[INFO] 2021-04-27 19:18:09,387 - Total elapsed time: 14.3s\n",
      "[INFO] 2021-04-27 19:18:09,387 - Instance Hardness analysis finished.\n",
      "Passou: 61_iris 5NN 4/5 H+U\n",
      "Testando: 61_iris 5NN 4/5 LSC\n",
      "{'name': 'Highest LSC Sampling', 'measure': 'LSC', 'sortby': ['feature_LSC'], 'ascending': [False]}\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/bin/pyhard\", line 5, in <module>\n",
      "    from pyhard.cli import cli\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/pyhard/__init__.py\", line 3, in <module>\n",
      "    from .measures import ClassificationMeasures\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/pyhard/measures.py\", line 12, in <module>\n",
      "    from .base import BaseMeasures\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/pyhard/base.py\", line 6, in <module>\n",
      "    import holoviews as hv\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/holoviews/__init__.py\", line 12, in <module>\n",
      "    from .annotators import annotate                         # noqa (API import)\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/holoviews/annotators.py\", line 10, in <module>\n",
      "    from panel.pane import PaneBase\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/panel/__init__.py\", line 1, in <module>\n",
      "    from . import layout # noqa\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/panel/layout/__init__.py\", line 1, in <module>\n",
      "    from .accordion import Accordion # noqa\n",
      "  File \"/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/panel/layout/accordion.py\", line 5, in <module>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'feature_LSC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/importing_datasets.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mph_strategy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpyhard_strategies_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testando: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_bag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mph_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyhard_strategies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_bag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mph_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mtotal_performance_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/active_learning/data/act_len labs/pyhard/importing_datasets.py\u001b[0m in \u001b[0;36mpyhard_strategies\u001b[0;34m(X_raw, y_raw, idx_data, idx_bag, classifier, init_size, cost, strategy)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metadata.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sortby'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ascending'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instances'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_bag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   5453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5454\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5455\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5457\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/ahmou/Onedrive/Documentos/ubuntu_wd/act_len/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1682\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'feature_LSC'"
     ]
    }
   ],
   "source": [
    "pyhard_strategies_names = ['H','U','H+U','LSC','N2','F3']\n",
    "\n",
    "for ds in datasets:\n",
    "    for classifier in classifiers:\n",
    "        X_raw, y_raw, idx_data, dataset_name = which_arff_dataset(ds)\n",
    "        #para cada i em idx_bag (\"n_splits\") (1 a 5)\n",
    "        for idx_bag in range(n_splits):\n",
    "            for ph_strategy in pyhard_strategies_names:\n",
    "                tqdm.write(\"Testando: \" + str(ds[:-5]) + \" \" + str(classifier) + \" \" + str(idx_bag) + \"/\" + str(n_splits) + \" \" + ph_strategy)\n",
    "                result = pyhard_strategies(deepcopy(X_raw), deepcopy(y_raw), idx_data, idx_bag, classifier, k, cost, ph_strategy)\n",
    "                result['dataset'] = ds[:-5]\n",
    "                total_performance_history.append(result)\n",
    "                tqdm.write(\"Passou: \" + str(ds[:-5]) + \" \" + str(classifier) + \" \" + str(idx_bag) + \"/\" + str(n_splits) + \" \" + ph_strategy)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "functions = [\"uncertain_sampling\", \"random_sampling\", \"query_by_committee\", \"exp_error_reduction\", \"exp_model_change\"]\n",
    "parameters = \"(deepcopy(X_raw), deepcopy(y_raw), idx_data, idx_bag, classifier, k, cost)\"\n",
    "\n",
    "for ds in tqdm(datasets,  desc =\"Dataset\"):\n",
    "    for classifier in classifiers:\n",
    "        X_raw, y_raw, idx_data, dataset_name = which_arff_dataset(ds)\n",
    "        #para cada i em idx_bag (\"n_splits\") (1 a 5)\n",
    "        for idx_bag in range(n_splits):\n",
    "            for func in functions:\n",
    "                tqdm.write(\"Testando: \" + str(ds[:-5]) + \" \" + str(classifier) + \" \" + str(idx_bag+1) + \"/\" + str(n_splits) + \" \" + func)\n",
    "                result = eval(func+parameters)\n",
    "                result['dataset'] = ds[:-5]\n",
    "                total_performance_history.append(result)\n",
    "                tqdm.write(\"Passou: \" + str(ds[:-5]) + \" \" + str(classifier) + \" \" + str(idx_bag+1) + \"/\" + str(n_splits) + \" \" + func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_performance_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(total_performance_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['Strategy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df\n",
    "df2.groupby(['Strategy', 'classifier']).agg({'performance_history':['mean','std'],'time_elapsed':['mean','std'], 'sample_size':['mean','std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_mean = df2.groupby(['Strategy', 'classifier']).mean()\n",
    "performance_std = df2.groupby(['Strategy', 'classifier']).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('performance_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Strategy != \"Query by Committee\"].sort_values('performance_history', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Strategy == \"Expected Error Reduction\"].sort_values('time_elapsed', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data= df,\n",
    "    x=\"performance_history\", y=\"time_elapsed\",\n",
    "    hue=\"Strategy\", size=\"sample_size\",\n",
    "    palette=sns.color_palette(n_colors=10), sizes=(100, 300), alpha=0.3\n",
    ")\n",
    "g.ax.xaxis.grid(True, \"minor\", linewidth=.25)\n",
    "g.ax.yaxis.grid(True, \"minor\", linewidth=.25)\n",
    "_ = g.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data= performance_mean,\n",
    "    x=\"performance_history\", y=\"time_elapsed\",\n",
    "    hue=\"Strategy\", size=\"sample_size\", style=\"classifier\",\n",
    "    palette=sns.color_palette(n_colors=10), sizes=(100, 300), alpha=0.3\n",
    ")\n",
    "g.ax.xaxis.grid(True, \"minor\", linewidth=.25)\n",
    "g.ax.yaxis.grid(True, \"minor\", linewidth=.25)\n",
    "_ = g.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data= df[(df.Strategy != \"Uncertain Sampling\") & (df.Strategy != \"Query by Committee\")],\n",
    "    x=\"performance_history\", y=\"time_elapsed\",\n",
    "    hue=\"Strategy\", size=\"sample_size\",\n",
    "    palette=sns.color_palette(n_colors=3), sizes=(100, 300), alpha=0.3\n",
    ")\n",
    "g.ax.xaxis.grid(True, \"minor\", linewidth=.25)\n",
    "g.ax.yaxis.grid(True, \"minor\", linewidth=.25)\n",
    "_ = g.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data= df[(df.Strategy == \"Uncertain Sampling\") | (df.Strategy == \"Query by Committee\")],\n",
    "    x=\"performance_history\", y=\"time_elapsed\",\n",
    "    hue=\"Strategy\", size=\"sample_size\",\n",
    "    palette=sns.color_palette(n_colors=2), sizes=(100, 300), alpha=0.3\n",
    ")\n",
    "g.ax.xaxis.grid(True, \"minor\", linewidth=.25)\n",
    "g.ax.yaxis.grid(True, \"minor\", linewidth=.25)\n",
    "_ = g.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baixando datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "p_bar = tqdm(datalist)\n",
    "for dataset_id in p_bar:\n",
    "    X_raw, y_raw, idx_data, dataset_name = which_oml_dataset(dataset_id)\n",
    "    p_bar.set_description(f'\"{dataset_name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = \"1465_breast-tissue.arff\"\n",
    "\n",
    "X_raw, y_raw, idx_data, dataset_name = which_arff_dataset(ds)\n",
    "   \n",
    "from modAL.uncertainty import classifier_uncertainty\n",
    "\n",
    "print(len(np.unique(y_raw)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw[idx_data[idx_bag][TRAIN]], y_raw[idx_data[idx_bag][TRAIN]], train_size= len(np.unique(y_raw)), stratify = y_raw[idx_data[idx_bag][TRAIN]])\n",
    "print(y_train)\n",
    "\n",
    "learner = ActiveLearner (\n",
    "    estimator= which_classifier(classifier), #cls,\n",
    "    query_strategy=uncertainty_sampling,\n",
    "    X_training = X_train, y_training = y_train # AL AJUSTA O CLASSIFIER \n",
    ")\n",
    "\n",
    "uncertain_sample_score = learner.score(X_test, y_test)\n",
    "\n",
    "total_of_samples = 1\n",
    "while (total_of_samples != cost):\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, train_size=0.03)\n",
    "\n",
    "    idx = np.random.choice(range(len(idx_data[idx_bag][TRAIN])), size=init_size, replace=False)\n",
    "    X_train, y_train = X_raw[idx_data[idx_bag][TRAIN][idx]], y_raw[idx_data[idx_bag][TRAIN][idx]]\n",
    "\n",
    "    if classifier_uncertainty(learner, X_train[0].reshape(1,-1)) > 0.2:\n",
    "        #print(\"IF\", learner.score(X_test, y_test))\n",
    "        learner.teach(X_train, y_train)\n",
    "        uncertain_sample_score = learner.score(X_test, y_test)\n",
    "        performance_history.append(uncertain_sample_score)\n",
    "    total_of_samples = total_of_samples + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size= len(np.unique(y_raw)) + init_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
